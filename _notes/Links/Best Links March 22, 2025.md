---
title: Best Links March 22, 2025
date: 2025-03-16
---
[The God's Eye View is Death to Poetry](https://hollisrobbinsanecdotal.substack.com/p/the-gods-eye-view-is-death-to-poetry?utm_source=post-email-title&publication_id=1004053&post_id=159102622&utm_campaign=email-post-title&isFreemail=true&r=i22m&triedRedirect=true&utm_medium=email)

A weird, beautiful, and interesting essay on how having the ability to pilot a drone on our phones changes the way we relate to the world.

>Our drone-enabled perspective risks exchanging this rich imaginative territory for the illusion of complete understanding, trading the fertile constraints of human vision for a technological approximation of divine sight that, paradoxically, may leave us seeing less rather than more. In gaining the god’s eye view, we may lose the very ground from which poetry grows: the beautiful incompleteness of the human perspective.

Love the idea of the "fertile constraints" of human vision. 

>AI processes massive amounts of data in seconds, simultaneously, synthesizing countless literary traditions, voices, and worldviews. It’s the opposite of poetry, which requires commitment to a singular voice, a particular way of seeing—constraints that AI, with its computational omniscience, integrating of all perspectives, cannot inhabit.

I think we have to be very wary of assuming that the AIs will create such high-fidelity maps that the map vs territory distinction is no longer relevant. The fact the *fertile constraints* will continue to exist leaves room for value-added work in most fields. 

I have found I've been most impressed by llm responses outside of my direct area of expertise because I can't judge how realistic the answer actually is. On many questions, llms lack the type of territory-level knowledge that is most critical and [[The relationship between expertise and value is convex|valuable]] in moving from thinking you understand something to *actually* understanding it.  It is likely there is [[On the News|Gell-Mann Amnesia]] effect working on me for at least some of the llm results that seem so impressive. 

If the stuff I work on and find interesting is anywhere close to representative, it will be years before AIs can fully substitute for just being the person that knows the guy who knows the guy who knows the random bit of information needed to understand the territory. One reason it will be years is because those who *know* have a huge interest in slowing the diffusion of this [*metis*-type](https://en.wikipedia.org/wiki/Seeing_Like_a_State) knowledge.

[Jason Zweig on Kahneman's Assisted Suicide](https://www.wsj.com/arts-culture/books/daniel-kahneman-assisted-suicide-9fb16124)

>Kahneman’s friend Annie Duke, a decision theorist and former professional poker player, published a book in 2022 titled “Quit: The Power of Knowing When to Walk Away.” In it, she wrote, “Quitting on time will usually feel like quitting too early.” <br>
><br>She is frustrated by his decision. “There’s a big difference between it feeling early and it actually being too early,” she says. “You’re not terminal, you’re fine. Why aren’t you taking the outside view? Why aren’t you listening to people who will give you good objective advice? Why are you doing this?”

[Rob Henderson: Sometimes Money Can Destroy You Faster Than Poverty](https://www.robkhenderson.com/p/sometimes-money-can-destroy-you-faster?utm_source=post-email-title&publication_id=800237&post_id=159090892&utm_campaign=email-post-title&isFreemail=true&r=i22m&triedRedirect=true&utm_medium=email)

>As a teenager, I noticed something strange about myself and many of the other young males I grew up around. So often, our worst moments didn’t happen when we were broke, but right after payday—when a sudden influx of cash allowed us to indulge in alcohol or drugs. Then the hangover would come, along with fleeting moments of clarity and regret. It’s a cycle I explore in **[my memoir](https://www.simonandschuster.com/books/Troubled/Rob-Henderson/9781982168537)**.<br><br>Recognizing the dangers of wealth, as articulated by Fitzgerald, taught me to be cautious of sudden windfalls of good fortune, to respect the dangers of excess, and to understand that self-discipline and restraint matter most precisely when it feels least necessary. It’s a constant reminder that character isn’t tested only by poverty and hardship, but equally—and perhaps even more dangerously—by success.

[Some random notes on Preparing for the Intelligence Explosion](https://www.forethought.org/research/preparing-for-the-intelligence-explosion)

>The development of AI that can meaningfully substitute for human research labour would probably drive very rapid technological development, compressing decades of scientific, technological and intellectual development into years or months.

There is an important difference between invention vs diffusion. [Just because we invent far UVC, for example, which can solve a really big human challenge, does not mean that we actually roll it out.](https://www.worksinprogress.news/p/flipping-the-switch-on-far-uvc) Convincing the humans to operationalize things is a different challenge. I don't have enough knowledge of this space to know what we are currently bottlenecked by. Take a medical advance for instance... we currently spend 1 billion dollars and many months (maybe years) to test it all out. I suppose the AIs could do this *in-silico* but wouldn't we want (or mandate) testing it in longer-term clinal trials?

>enough material abundance to give everyone a lifestyle that today’s billionaires would envy

This feels like an insane statement. I hope that it is true, but I'm not even sure what that would look like. Everyone has megayachts and private jets? all 8 billion of us? Everyone has their own planet and space ship?

>Prevent extreme and hard-to-reverse concentration of power , by establishing institutions and policies now. For instance, we can ensure that data centers and essential components of the semiconductor supply chain are distributed across democratic countries and that access to frontier AI continues to be available to many parties, both within and across countries.

This seems like a pretty large assumption that competition is the answer here. Why shouldn't we expect a race to the bottom if it becomes a competition among many parties? Maybe this would be better in a monopoly.

>Empower responsible actors: Increase the chance that those actors who wield the most power over the development of superintelligence (such as politicians and AI company CEOs) are responsible, competent, and accountable.

Ah yes, just like the adults in the room currently. By what mechanism do we intend to do this?

> Get started early on institutional design for new areas of governance , including on the rights of digital beings and the legal framework for property claims on offworld resources.

Need to learn more about digital beings. There seems to be the assumption of consciousness in EA and EA-adjacent spaces that doesn't feel fully fleshed out. How, fundamentally, can next-token predictors experience suffering?